Keilani Caruso kcaruso4 kcaruso4@jhu.edu

Discussion:
Part A:
1. Iterating over a MeasuredArray should affect the accesses but not the mutations count. Because next() and hasNext() access the value at a specific index and the length of the array every time it is called, the access count should be increased accordingly. The mutation count should not be affected though because next() and hasNext() do not make changes to the elements of the array. Because ArrayIterator is an inner private class of SimpleArray class, MeasureArray cannot inherit and override the relevant methods because it does not have access to ArrayIterator from inheritance.

Part B:
The intentional mistake that within the provided data files is located in the ascending.data file. Theoretically if the values in the file were imported as integers, then the sort functions would only have the same number of mutations as the length of the array. The fact that the mutation count for all the sorts are greater than the length of the array indicates that the values are being sorted after being placed in the array. Because the values are stored in the arrays as strings and strings are compared based on ascii value, then the data in the file is not actually in ascending order. Therefore that is why the functions sort the ascending data to be in proper order.


1. The actual running times do correspond to the asymptotic complexity as I would expect. Because insertion and bubble sort perform O(N^2) comparisons, they should all approximately take around the same time where no sort is significantly slower or faster than the other which was apparent in the running times of the sorts. Even though the discrepancy between the running times at larger chunks of data becomes more apparent (for example when you run PolySort on 7000 values) the difference between these sorts is not as drastic as the difference with Gnome sort which does not make O(N^2) comparisons. Bubble sort does take more time than insertion sort (which it should) because bubble sort must iterate through all the values in the array for every pass (unless a smart cutoff is reached) while insertion sort does not. Theoretically, because insertion sort swaps the value every time until it has found its proper position it should be slower than selection sort which only swaps once. But I found that sometimes insertion sort is quicker because it does not have to iterate through the entire array (unlike selection sort) every pass. Therefore which ever sort is quicker is dependent on the order of the data. The running time corresponds for selection sort because although it only makes O(N) swaps, it sill must perform O(N^2) comparisons. Therefore its time being approximately around the same as insertion sort makes sense. And yes the running time does corresponds to the complexity of GenomeSort because it makes a lot comparison but very few changes to the array.

2. One practical difference that I implemented in my definition of bubble sort is the smart cutoff. Because bubble sort "bubbles" out the largest value, if no swaps are made after a pass then the sort can end. A practical difference with insertion sort is that it does not require to iterate through all of the values of the array to find the right spot for the current value it is sorting. The sort simply puts the value as far left as it can go it. A practical difference for selection sort is that it only swaps the values when it finds the proper position. A practical difference of GenomeSort is that when it swaps values it reduces i by a factor of one and continues to swap at previous indices until all possible swaps are made. Therefore GenomeSort does not move forward in the array until the bottom half is completely sorted.

3. The kind of data does mater when you are sorting because of how the sorts look at the data. For example bubble and insertion took the longest to sort the descending data, then the random data, then the ascending data. For bubble and insertion they had to move every single value across the array in each pass. Random was better because more lower values were closer to the front which allowed the sorts to move less and ascending took even less time because they were already in order. If the algorithm receive data in ascending order then it should merely have to check to make sure that the data is properly sorted (be much quicker). The algorithms should perform normally for the random data because how the values are ordered cannot be predetermined. When receiving descending order data it should move the data straight away to the correct index (length - original index) and potentially check the array at the end to make sure all is sorted properly. If selection sort knows the data is in ascending order then it should be able to make a single pass and determine that the smallest value not at the index it is looking at is not smaller than the current index. It should behave normally though for descending and random data. Because selection sort is dependent on comparisons (assuming swap does not take that much time) then it should take approximately the same amount of time for any type of data. For GenomeSort because it relies mainly on comparison, we should expect it to be much quicker sorting ascending data rather than descending and random data. We would assume sorting random data would be completed more quickly because it is most likely not the worst case so less swaps and comparisons would be made. 



Part C:
1. C(n) = n-1 + (n-1)(n)
I determined the solution by looking at the three comparison statements found on lines 3, 5 and 6. I got the first term in the equation (n-1) because the outer for loop will go through n-1 iterations, therefore performing n-1 comparisons. The next term I got from lines 5 and 6. The cost of these comparisons ranges from 1 to n-1 because they are dependent on the value of i from the outer loop. Therefore the cost to perform each of these comparisons is (n-1)(n)/2. Because there are two of these costs, they reduce to (n-1)(n).

2. A(n) = 1 + 6*(n-1) + (n-1)(n)
I determined the solution by looking at the assignment commands on lines 3, 4, 5, 7, 10, 11, and 12. The first term in the equation comes from the assignment int i = 0 which only happens once, at the start of the outer for loop. The next term (6*(n-1)) comes from the lines 3 (i++;), 4 (max = i), 5 (int j = i), 10 (temp = a[i]), 11 (a[i] = a[max]), and 12 (a[max] = temp). Each of these lines of code will occur the same amount of times as the for loop iterates through each value of i which is n-1. Collectively they cost a total of 6*(n-1). The next term ((n-1)(n)) comes from j++ on line 5 and max = j on line 7. Because the cost of that operations ranges from 1 to n-1 because the statements the loop is in is dependent on the outer loop, the accumulative cost for each is (n-1)(n)/2. Therefore the cost of both of them together is (n-1)(n).
